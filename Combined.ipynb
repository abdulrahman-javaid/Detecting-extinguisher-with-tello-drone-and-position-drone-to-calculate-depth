{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6784eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import PIL.Image as pil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "import networks\n",
    "from utils import download_model_if_doesnt_exist\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "from djitellopy import tello\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from socket import *\n",
    "import sys\n",
    "import pygame\n",
    "from PIL import Image\n",
    "\n",
    "import glob\n",
    "import argparse\n",
    "import matplotlib\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from keras.models import load_model\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.layers import Layer, InputSpec\n",
    "import keras.utils.conv_utils as conv_utils\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import pandas as pd\n",
    "\n",
    "from djitellopy import tello\n",
    "import cv2 \n",
    "import uuid\n",
    "import os\n",
    "import time\n",
    "import wget\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from google.protobuf import text_format\n",
    "from Tensorflow import config_util\n",
    "from Tensorflow import label_map_util\n",
    "from Tensorflow import visualization_utils as viz_utils\n",
    "from Tensorflow import New\n",
    "from Tensorflow import model_builder\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b21a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from djitellopy import tello\n",
    "\n",
    "drone = tello.Tello()\n",
    "drone.connect()\n",
    "print(drone.get_battery())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafba102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DepthNorm(x, maxDepth):\n",
    "    return maxDepth / x\n",
    "\n",
    "def predict(model, images, minDepth=10, maxDepth=1000, batch_size=2):\n",
    "    # Support multiple RGBs, one RGB image, even grayscale Z\n",
    "    if len(images.shape) < 3: images = np.stack((images, images, images), axis=2)\n",
    "    if len(images.shape) < 4: images = images.reshape((1, images.shape[0], images.shape[1], images.shape[2]))\n",
    "    # Compute predictions\n",
    "    predictions = model.predict(images, batch_size=batch_size)\n",
    "    # Put in expected range\n",
    "    return np.clip(DepthNorm(predictions, maxDepth=maxDepth), minDepth, maxDepth) / maxDepth\n",
    "\n",
    "def scale_up(scale, images):\n",
    "    pass\n",
    "\n",
    "def load_images(image_files):  # required\n",
    "    loaded_images = []\n",
    "    for file in image_files:\n",
    "        x = np.clip(np.asarray(Image.open(file), dtype=float) / 255, 0, 1)\n",
    "        loaded_images.append(x)\n",
    "    return np.stack(loaded_images, axis=0)\n",
    "\n",
    "def to_multichannel(i):\n",
    "    if i.shape[2] == 3: return i\n",
    "    i = i[:, :, 0]\n",
    "    return np.stack((i, i, i), axis=2)\n",
    "\n",
    "def display_images(outputs, inputs=None, gt=None, is_colormap=True, is_rescale=True):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import skimage\n",
    "    from skimage.transform import resize\n",
    "    plasma = plt.get_cmap('plasma')\n",
    "    shape = (outputs[0].shape[0], outputs[0].shape[1], 3)\n",
    "    all_images = []\n",
    "    for i in range(outputs.shape[0]):\n",
    "        print(i)\n",
    "        print(range(outputs.shape[0]))\n",
    "        imgs = []\n",
    "        if isinstance(gt, (list, tuple, np.ndarray)):\n",
    "            x = to_multichannel(gt[i])\n",
    "            x = resize(x, shape, preserve_range=True, mode='reflect', anti_aliasing=True)\n",
    "            imgs.append(x)\n",
    "        if is_colormap:\n",
    "            rescaled = outputs[i][:, :, 0]\n",
    "            if is_rescale:\n",
    "                rescaled = rescaled - np.min(rescaled)\n",
    "                rescaled = rescaled / np.max(rescaled)\n",
    "            imgs.append(plasma(rescaled)[:, :, :3])\n",
    "        else:\n",
    "            imgs.append(to_multichannel(outputs[i]))\n",
    "        img_set = np.hstack(imgs)\n",
    "        all_images.append(img_set)\n",
    "    all_images = np.stack(all_images)\n",
    "    return skimage.util.montage(all_images, multichannel=True, fill=(0, 0, 0))\n",
    "\n",
    "def evaluate(model, rgb, depth, crop, batch_size=6, verbose=False):\n",
    "    pass\n",
    "\n",
    "def compute_errors(gt, pred):\n",
    "    pass\n",
    "\n",
    "def load_test_data(test_data_zip_file='nyu_test.zip'):\n",
    "    pass\n",
    "\n",
    "def save_images(filename, outputs, inputs=None, gt=None, is_colormap=True, is_rescale=False):\n",
    "    pass\n",
    "\n",
    "class BilinearUpSampling2D(Layer):\n",
    "    def __init__(self, size=(2, 2), data_format=None, **kwargs):\n",
    "        super(BilinearUpSampling2D, self).__init__(**kwargs)\n",
    "        self.data_format = K.image_data_format().lower()\n",
    "        self.size = conv_utils.normalize_tuple(size, 2, 'size')\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            height = self.size[0] * input_shape[2] if input_shape[2] is not None else None\n",
    "            width = self.size[1] * input_shape[3] if input_shape[3] is not None else None\n",
    "            return (input_shape[0], input_shape[1], height, width)\n",
    "        elif self.data_format == 'channels_last':\n",
    "            height = self.size[0] * input_shape[1] if input_shape[1] is not None else None\n",
    "            width = self.size[1] * input_shape[2] if input_shape[2] is not None else None\n",
    "            return (input_shape[0], height, width, input_shape[3])\n",
    "    def call(self, inputs):\n",
    "        input_shape = K.shape(inputs)\n",
    "        if self.data_format == 'channels_first':\n",
    "            height = self.size[0] * input_shape[2] if input_shape[2] is not None else None\n",
    "            width = self.size[1] * input_shape[3] if input_shape[3] is not None else None\n",
    "        elif self.data_format == 'channels_last':\n",
    "            height = self.size[0] * input_shape[1] if input_shape[1] is not None else None\n",
    "            width = self.size[1] * input_shape[2] if input_shape[2] is not None else None\n",
    "        return tf.image.resize(inputs, [height, width], method=tf.image.ResizeMethod.BILINEAR)\n",
    "    def get_config(self):\n",
    "        config = {'size': self.size, 'data_format': self.data_format}\n",
    "        base_config = super(BilinearUpSampling2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72adb43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model', default='nyu.h5', type=str, help='Trained Keras model file.')\n",
    "parser.add_argument('--input', default='centered.png', type=str, help='Input filename or folder.')\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "custom_objects = {'BilinearUpSampling2D': BilinearUpSampling2D, 'depth_loss_function': None}\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = load_model(args.model, custom_objects=custom_objects, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e979d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dense():\n",
    "    x=time.time()\n",
    "    inputs = load_images(glob.glob(args.input))\n",
    "    outputs = predict(model,inputs)\n",
    "    xx=time.time()\n",
    "    print(\"Time delay of depth calculation is \",xx-x)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e35957",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'model' \n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'\n",
    "\n",
    "paths = {\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow','images'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow',CUSTOM_MODEL_NAME),\n",
    " }\n",
    "\n",
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9b228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e34503",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Real Time Detections\n",
    "\n",
    "drone.streamon()\n",
    "time.sleep(1)\n",
    "drone.takeoff()\n",
    "# time.sleep(3)\n",
    "drone.send_rc_control(0,0,0,0)\n",
    "width = 640 # Do not change this because calculations are built on this value #int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) \n",
    "height = 480 # Do not change this because calculations are built on this value #int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "rl,fb,ud,y = 0, 0, 0, 0\n",
    "speed = 18\n",
    "angle = drone.get_yaw()\n",
    "print (angle)\n",
    "t1 = time.time()\n",
    "k = 0\n",
    "while True:\n",
    "    print (\"new loop started\")\n",
    "    i = 0\n",
    "    frame = drone.get_frame_read().frame\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    _, ymin, xmin, ymax, xmax = New.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.53,\n",
    "                agnostic_mode=False)\n",
    "    \n",
    "    img = cv2.resize(image_np_with_detections, (640, 480))\n",
    "    cv2.imshow('object detection', img)\n",
    "\n",
    "    if ymin != 0:\n",
    "        print (\"detection\")\n",
    "        i, j = 0, 0 \n",
    "        ymin = int(ymin*480)\n",
    "        ymax = int(ymax*480)\n",
    "        xmin = int(xmin*640)\n",
    "        xmax = int(xmax*640)\n",
    "        \n",
    "        xlength = xmax - xmin\n",
    "        ylength = ymax - ymin\n",
    "        \n",
    "        Xcenter_point = (xmax + xmin)/2 \n",
    "        Ycenter_point = (ymax + ymin)/2\n",
    "\n",
    "        delta = np.array([Xcenter_point, Ycenter_point]) - np.array([width/2, height/2])\n",
    "        BArea = xlength * ylength # object detected Box area\n",
    "        IArea = width * height # image area from the drone camera assuming width always = 640 and height = 480\n",
    "        RArea = BArea/IArea*100 # box to image area ratio\n",
    "        print (RArea)\n",
    "        \n",
    "        if abs(RArea) < 2.5:\n",
    "            fb = speed # forward/backward\n",
    "            drone.send_rc_control(rl,fb,ud,y)\n",
    "        \n",
    "        elif abs(RArea) < 6 and abs(RArea) > 2.5:\n",
    "            fb = 0\n",
    "            drone.send_rc_control(rl,fb,ud,y)\n",
    "            if abs(delta[0]) > 5:\n",
    "                if delta[0] > 0:\n",
    "                    rl = speed\n",
    "                    drone.send_rc_control(rl,fb,ud,y)\n",
    "                else:\n",
    "                    rl = -speed\n",
    "                    drone.send_rc_control(rl,fb,ud,y)\n",
    "            else:\n",
    "                rl = 0\n",
    "                i = 1\n",
    "                drone.send_rc_control(rl,fb,ud,y)\n",
    "                    \n",
    "            if abs(delta[1]) > 5:\n",
    "                if delta[1] > 0:\n",
    "                    ud = -speed\n",
    "                    drone.send_rc_control(rl,fb,ud,y)\n",
    "                else:\n",
    "                    ud = speed\n",
    "                    drone.send_rc_control(rl,fb,ud,y)\n",
    "            else: \n",
    "                ud = 0\n",
    "                j = 1\n",
    "                drone.send_rc_control(rl,fb,ud,y)\n",
    "                \n",
    "            if i == 1 and j == 1:\n",
    "                t2 = time.time()\n",
    "                cv2.imwrite('centered.png', frame)\n",
    "                drone.send_rc_control(0,0,0,0)\n",
    "                outputs = Dense()\n",
    "                x = outputs[0][119][159][0]\n",
    "                outputs_1 = x + 0.1303 * x\n",
    "                outputs_2 = x - 0.1303 * x\n",
    "                \n",
    "                print (\"The object is in the range of \", outputs_1, \" and \", outputs_2)\n",
    "                print (\"The total time from first detection to centering is\", t2-t1)\n",
    "                drone.land()\n",
    "                sleep(5)\n",
    "                \n",
    "        elif abs(RArea) > 6:\n",
    "            fb = - speed\n",
    "            drone.send_rc_control(rl,fb,ud,y)\n",
    "    \n",
    "    else: \n",
    "        drone.send_rc_control(0,0,0,0)\n",
    "        print (\"no detection\")\n",
    "        sleep(0.1)\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        #cv2.destroyallwindows()\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
